{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1jkgi3U1GBIEybA_5X04ODoZO1UHC4Njb",
      "authorship_tag": "ABX9TyMJHo6BGKX6ndnYSnBbl9pq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinux-l5d/PROJ002/blob/main/animal_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "41_E8uNDPdP0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATADIR = \"animal10\"\n",
        "WIDTH = 200\n",
        "HEIGHT = 200"
      ],
      "metadata": {
        "id": "aM5UXGiw3dlV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_zip = \"/content/drive/MyDrive/INFO002/animal-10.zip\"\n",
        "with zipfile.ZipFile(data_zip,\"r\") as zip_ref:\n",
        "    zip_ref.extractall(DATADIR)"
      ],
      "metadata": {
        "id": "oymeYVnPvmhw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run on graphic card if possible\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"nb gpus\", len(gpus))\n",
        "if gpus:\n",
        "  # Restrict TensorFlow to only use the first GPU\n",
        "  try:\n",
        "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
        "  except RuntimeError as e:\n",
        "    # Visible devices must be set before GPUs have been initialized\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-Vm7KYjP2jK",
        "outputId": "326296ed-6711-486d-8e57-06c246e7503f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb gpus 1\n",
            "1 Physical GPUs, 1 Logical GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate = {'cane': 'dog', 'cavallo': 'horse', 'elefante': 'elephant', 'farfalla': 'butterfly', 'gallina': 'chicken', 'gatto': 'cat', 'mucca': 'cow', 'pecora': 'sheep', 'scoiattolo': 'squirrel', 'dog': 'cane', 'elephant': 'elefante', 'butterfly': 'farfalla', 'chicken': 'gallina', 'cat': 'gatto', 'cow': 'mucca', 'spider': 'ragno', 'squirrel': 'scoiattolo', 'horse': 'cavallo', 'ragno': 'spider', 'sheep': 'pecora'}\n",
        "CATEGORIES = [translate[name] for name in listdir(DATADIR + \"/raw-img\")]\n",
        "CATEGORIES.sort()\n",
        "print(list(enumerate(CATEGORIES)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuQZawFLy3Zg",
        "outputId": "7df8571c-d2b4-406a-caad-c4d171903ec4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 'butterfly'), (1, 'cat'), (2, 'chicken'), (3, 'cow'), (4, 'dog'), (5, 'elephant'), (6, 'horse'), (7, 'sheep'), (8, 'spider'), (9, 'squirrel')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataclass\n",
        "# class Photo:\n",
        "#   path: str\n",
        "#   animal: str\n",
        "\n",
        "#   def load(self):\n",
        "#     return Image.open(self.path).convert(\"RGB\").resize((WIDTH,HEIGHT))\n",
        "\n",
        "#   def variations(self):\n",
        "#     img = self.load()\n",
        "#     return [img.transpose(Image.FLIP_LEFT_RIGHT),\n",
        "#             img.transpose(Image.FLIP_TOP_BOTTOM),\n",
        "#             img.transpose(Image.ROTATE_90),\n",
        "#             img.resize((50,50)).resize((WIDTH,HEIGHT))]\n",
        "#   def tagI(self) -> int:\n",
        "#     return CATEGORIES.index(self.animal)\n",
        "#   def tagS(self) -> str:\n",
        "#     return self.animal\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Collection:\n",
        "  path = Path(DATADIR + \"/raw-img\")\n",
        "  train_perct = 0.8\n",
        "\n",
        "  def getCategory(self, category: str) -> pd.Series:\n",
        "    dirsp = translate.get(category, None)\n",
        "    if dirsp == None:\n",
        "      raise Exception(\"Invalid category\")\n",
        "    imgs = list(self.path.glob(dirsp + \"/*\"))\n",
        "    filenames = pd.Series(imgs, name=\"Filepath\").astype(str)\n",
        "    labels = pd.Series([category for _ in range(len(imgs))], name=\"Label\")\n",
        "    return pd.concat([filenames, labels], axis=1)\n",
        "\n",
        "  def computeMaxs(self, maxreq):\n",
        "    lenghts = {k: len(self.getCategory(k)) for k in CATEGORIES}\n",
        "    total = sum(lenghts.values())\n",
        "    return {k: round((v/total)*maxreq) for k, v in lenghts.items()}\n",
        "\n",
        "  def getTrain(self, maxs={}):\n",
        "      out = []\n",
        "      for category in CATEGORIES:\n",
        "          df = self.getCategory(category)\n",
        "          end = maxs.get(category, len(df))\n",
        "          end = round(end * self.train_perct)\n",
        "          out.append(df[:end])\n",
        "      return pd.concat(out)\n",
        "\n",
        "  def getTest(self, maxs={}):\n",
        "      out = []\n",
        "      for category in CATEGORIES:\n",
        "          df = self.getCategory(category)\n",
        "          end = maxs.get(category, len(df))\n",
        "          start = round(end * self.train_perct)\n",
        "          out.append(df[start:end])\n",
        "      return pd.concat(out)\n"
      ],
      "metadata": {
        "id": "ODG5Uhcz0Ije"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_row(*imgs):\n",
        "    _, ax = plt.subplots(1, len(imgs), figsize=(20, 20))\n",
        "    if not isinstance(ax, np.ndarray):\n",
        "        ax = np.array([ax])\n",
        "    for i, img in enumerate(imgs):\n",
        "        ax[i].imshow(img)\n",
        "        ax[i].axis('off')"
      ],
      "metadata": {
        "id": "uQ8FeOStBeZc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = Collection()\n",
        "#display_row(*c.getTrain()[2000].variations())\n",
        "\n",
        "m = c.computeMaxs(10_000)\n",
        "print(m)\n",
        "assert sum(m.values()) == 10_000\n",
        "assert len(c.getTrain(m)) + len(c.getTest(m)) == 10_000\n",
        "print(c.getTrain(m))\n",
        "del m # was used in previous version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70W2rk-5wERq",
        "outputId": "4f50b763-afa0-476b-e225-0143afcfa99a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'butterfly': 807, 'cat': 637, 'chicken': 1183, 'cow': 713, 'dog': 1858, 'elephant': 552, 'horse': 1002, 'sheep': 695, 'spider': 1842, 'squirrel': 711}\n",
            "                                              Filepath      Label\n",
            "0    animal10/raw-img/farfalla/OIP-HNpo_i1VSZXY9NQ3...  butterfly\n",
            "1    animal10/raw-img/farfalla/OIP-6Bam26g68QXMl0z2...  butterfly\n",
            "2    animal10/raw-img/farfalla/OIP-0nCXiQiaWGKe08X6...  butterfly\n",
            "3    animal10/raw-img/farfalla/OIP-kkshTVubNjIsktE2...  butterfly\n",
            "4    animal10/raw-img/farfalla/OIP-cilySFIjrc6QSJBe...  butterfly\n",
            "..                                                 ...        ...\n",
            "564  animal10/raw-img/scoiattolo/OIP-DLuAMgbGGOGW0r...   squirrel\n",
            "565  animal10/raw-img/scoiattolo/OIP-BFCOTEmVj1I9R7...   squirrel\n",
            "566  animal10/raw-img/scoiattolo/OIP-adLOsEpklYQOL5...   squirrel\n",
            "567  animal10/raw-img/scoiattolo/OIP-sMWZFznxn4dnm_...   squirrel\n",
            "568  animal10/raw-img/scoiattolo/OIP-auuw2Tn5WM35wa...   squirrel\n",
            "\n",
            "[8001 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen_train = ImageDataGenerator(rescale = 1./255,\n",
        "                                  width_shift_range=0.15,\n",
        "                                   height_shift_range=0.15,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True)\n",
        "datagen_test = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "JgS97uyjPKvq"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getGenerator(idg, df, batch_size=32):\n",
        "    return idg.flow_from_dataframe(\n",
        "        dataframe=df,\n",
        "        x_col=\"Filepath\",\n",
        "        y_col=\"Label\",\n",
        "        target_size=(WIDTH, HEIGHT),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        class_mode=\"categorical\"\n",
        "    )"
      ],
      "metadata": {
        "id": "L6nfIajiP2mn"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_train = getGenerator(datagen_train, c.getTrain())\n",
        "set_test = getGenerator(datagen_test, c.getTest())\n",
        "# set_test_blind = getGenerator(datagen_test, c.getTest()[\"Filepath\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvH_I4yJRpRs",
        "outputId": "db37091b-4f8e-4e47-90e9-1067213a5e07"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20943 validated image filenames belonging to 10 classes.\n",
            "Found 5236 validated image filenames belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\", input_shape=(WIDTH, HEIGHT, 3)),\n",
        "    # tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", input_shape=(WIDTH, HEIGHT, 3)),\n",
        "    # tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iF5fzDCIylb0",
        "outputId": "7f47c8dc-d1de-42d4-84e5-5136b6c113b8"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_13 (Conv2D)          (None, 198, 198, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 198, 198, 64)      256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 198, 198, 64)      0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 196, 196, 32)      18464     \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 196, 196, 32)      128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 196, 196, 32)      0         \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 1229312)           0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 256)               314704128 \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 314727338 (1.17 GB)\n",
            "Trainable params: 314727146 (1.17 GB)\n",
            "Non-trainable params: 192 (768.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"best.keras\", monitor=\"val_accuracy\", verbose=1, save_best_only=True, mode=\"max\")\n",
        "]\n",
        "\n",
        "model.fit(set_train,\n",
        "          validation_data = set_test,\n",
        "          validation_steps = len(set_test),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks,\n",
        "          batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbbe_VbD1Dhp",
        "outputId": "3b838966-a9b4-4959-eaa8-41523785baa9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 30.4263 - accuracy: 0.1836\n",
            "Epoch 1: val_accuracy improved from -inf to 0.19099, saving model to best.keras\n",
            "655/655 [==============================] - 359s 535ms/step - loss: 30.4263 - accuracy: 0.1836 - val_loss: 2.2396 - val_accuracy: 0.1910\n",
            "Epoch 2/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 2.2718 - accuracy: 0.1959\n",
            "Epoch 2: val_accuracy improved from 0.19099 to 0.19882, saving model to best.keras\n",
            "655/655 [==============================] - 357s 544ms/step - loss: 2.2718 - accuracy: 0.1959 - val_loss: 2.2943 - val_accuracy: 0.1988\n",
            "Epoch 3/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 2.1997 - accuracy: 0.2162\n",
            "Epoch 3: val_accuracy improved from 0.19882 to 0.22326, saving model to best.keras\n",
            "655/655 [==============================] - 357s 544ms/step - loss: 2.1997 - accuracy: 0.2162 - val_loss: 2.2662 - val_accuracy: 0.2233\n",
            "Epoch 4/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 2.1078 - accuracy: 0.2575\n",
            "Epoch 4: val_accuracy improved from 0.22326 to 0.26929, saving model to best.keras\n",
            "655/655 [==============================] - 355s 542ms/step - loss: 2.1078 - accuracy: 0.2575 - val_loss: 2.0503 - val_accuracy: 0.2693\n",
            "Epoch 5/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 2.0782 - accuracy: 0.2660\n",
            "Epoch 5: val_accuracy improved from 0.26929 to 0.29297, saving model to best.keras\n",
            "655/655 [==============================] - 342s 520ms/step - loss: 2.0782 - accuracy: 0.2660 - val_loss: 2.0807 - val_accuracy: 0.2930\n",
            "Epoch 6/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 2.1798 - accuracy: 0.2695\n",
            "Epoch 6: val_accuracy did not improve from 0.29297\n",
            "655/655 [==============================] - 320s 489ms/step - loss: 2.1798 - accuracy: 0.2695 - val_loss: 2.0320 - val_accuracy: 0.2890\n",
            "Epoch 7/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 2.0332 - accuracy: 0.2834\n",
            "Epoch 7: val_accuracy improved from 0.29297 to 0.29316, saving model to best.keras\n",
            "655/655 [==============================] - 346s 529ms/step - loss: 2.0332 - accuracy: 0.2834 - val_loss: 1.9938 - val_accuracy: 0.2932\n",
            "Epoch 8/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 2.0457 - accuracy: 0.2863\n",
            "Epoch 8: val_accuracy improved from 0.29316 to 0.30519, saving model to best.keras\n",
            "655/655 [==============================] - 352s 537ms/step - loss: 2.0457 - accuracy: 0.2863 - val_loss: 1.9829 - val_accuracy: 0.3052\n",
            "Epoch 9/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 1.9960 - accuracy: 0.2959\n",
            "Epoch 9: val_accuracy did not improve from 0.30519\n",
            "655/655 [==============================] - 315s 481ms/step - loss: 1.9960 - accuracy: 0.2959 - val_loss: 4.0909 - val_accuracy: 0.2145\n",
            "Epoch 10/10\n",
            "655/655 [==============================] - ETA: 0s - loss: 1.9808 - accuracy: 0.2985\n",
            "Epoch 10: val_accuracy did not improve from 0.30519\n",
            "655/655 [==============================] - 308s 470ms/step - loss: 1.9808 - accuracy: 0.2985 - val_loss: 2.0235 - val_accuracy: 0.2869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ec305bf04f0>"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"best.keras\")\n",
        "test_loss, test_acc = model.evaluate(set_test)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puxdvo43bD-4",
        "outputId": "58745f22-b2be-484f-f95d-1c537341808b"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "164/164 [==============================] - 11s 66ms/step - loss: 1.9829 - accuracy: 0.3052\n",
            "Test accuracy: 0.30519479513168335\n",
            "Test loss: 1.9829366207122803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred = model.predict(set_test_blind)\n",
        "\n",
        "# pred[0]"
      ],
      "metadata": {
        "id": "IOTHnH2VjFzX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}